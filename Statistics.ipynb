{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Concepts ################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers - https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "#https://medium.com/datadriveninvestor/finding-outliers-in-dataset-using-python-efc3fce6ce32\n",
    "\n",
    "#https://medium.com/codezillas/statistics-review-for-data-scientists-and-management-df8f94760221\n",
    "\n",
    "#In statistics, an outlier is an observation point that is distant from other observations.\n",
    "#The above definition suggests that outlier is something which is separate/different from the crowd\n",
    "\n",
    "#There are two types of analysis we will follow to find the outliers- \n",
    "#Uni-variate(one variable outlier analysis) and Multi-variate(two or more variable outlier analysis).\n",
    "# Discover outliers with visualization tools - Box plot-Wikipedia Definition,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This distribution describes the grouping or the density of the observations, called the probability density function.\n",
    "#https://machinelearningmastery.com/statistical-data-distributions/\n",
    "\n",
    "#A distribution is simply a collection of data, or scores, on a variable. Usually, these scores are arranged in order from \n",
    "#smallest to largest and then they can be presented graphically.\n",
    "\n",
    "#Distributions are often described in terms of their density or density functions.\n",
    "\n",
    "#Density functions are functions that describe how the proportion of data or likelihood of the proportion of observations \n",
    "#change over the range of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/datadriveninvestor/a-quick-guide-to-hypothesis-testing-8c95205f2a1c\n",
    "#https://medium.com/codezillas/statistics-review-for-data-scientists-and-management-df8f94760221\n",
    "#https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471 ---- very important\n",
    "#https://towardsdatascience.com/hypothesis-testing-in-machine-learning-using-python-a0dc89e169ce\n",
    "\n",
    "#In Hypothesis testing we make an assumption about the data and then perform investigation considering that our assumption is true\n",
    "#Now the observation we get from our investigation is used for validating our assumption.\n",
    "\n",
    "# It sounds confusing but please be patient everything will be clear as you go down.\n",
    "\n",
    "# Let me define some terms :\n",
    "# Null hypothesis(H0) : A null hypothesis is the assumption we made before performing any calculation and consider it to be “true”\n",
    "#initially.\n",
    "# Alternative hypothesis(H1) : An alternative hypothesis is simply opposite of null hypothesis if there is strong evidence against\n",
    "#null hypothesis then we move to alternative hypothesis.\n",
    "# P — Value : P-value is the probability for a given statistical model , when the null hypothesis is true. p-value is used as a \n",
    "#rejection point to provide the smallest level of significance at which the null hypothesis would be rejected.\n",
    "# Test Statistics : A value calculated from a sample or experiment. Test statistics can be any value like mean of a distribution,\n",
    "#frequency of observation or anything it provide evidence either in support or against of null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC and ROC curve - Relationship between sensivity(recall) and 1- specificity(-ve recall)\n",
    "#https://techgrabyte.com/10-machine-learning-algorithms-application/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Boosting\n",
    "\n",
    "https://www.youtube.com/watch?v=m-S9Hojj1as&index=16&list=PLVBorYCcu-xWBPu3o73uj2FJ_7dp6g-pr -Bagging and Boosting\n",
    "#Random forest is ensemble of decision tree. When single model is overfit or diff in accuracy is high so we will use ensemble.\n",
    "\n",
    "#Bagging - It is ensemble method where we use multiples models of same algoriths for diff subset of dataset randomdly.\n",
    "#And take the votes to the output.\n",
    "#Bagging is an ensemble technique mainly used to reduce the variance of our predictions by combining the results of multiple \n",
    "#classifiers modelled on different sub-samples of the same dataset. In Bagging, individual learner are trained in parallel.\n",
    "\n",
    "#Bossting - In this case, we give more emphasis on selecting datasets which gives wrong predicton in order to imporve accuracy.\n",
    "#Boosting builds on weak learners, and in an iterative fashion. In each iteration, a new learner is added, while all existing \n",
    "#learners are kept unchanged. All learners are weighted based on their performance (e.g., accuracy), and after a weak learner\n",
    "#is added, the data are re-weighted: examples that are misclassified gain more weights, while examples that are correctly\n",
    "#classified lose weights. Thus, future weak learners focus more on examples that previous weak learners misclassified.\n",
    "#Boosting helps in reduse the vairiance and overfitting of the model.\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier AdaBoostClassifier\n",
    "\n",
    "#Types of Boosting Algorithms\n",
    "#AdaBoost (Adaptive Boosting) - Mostly overfit like decision tree\n",
    "#Gradient Tree Boosting\n",
    "#XGBoost\n",
    "\n",
    "#Boosting is a method of converting a set of weak learners into a strong learner. \n",
    "#Many algorithms works with the concept of boosting but today, we will talk about three major boosting algorithms and will \n",
    "#look into their differences:\n",
    "\n",
    "#All these boosting methods differ on how they create the weak learners during the iterative process.\n",
    "\n",
    "#GBM generates learners during the learning process and  build first learner to predict labels and calculate the loss and it will build a second learner to predict the loss after the first step and so on. It minimizes the loss function (difference of actual and predictions).\n",
    "\n",
    "#Adaboost requires a set of weak learners before real learning process and assign the weights to these learners to be a strong learner. The weight of each learner is learned by whether it predicts a sample correctly or not. If a learner is mispredict a sample, the weight of the learner is reduced a bit. It will repeat such process until converge and accuracy increases.\n",
    "\n",
    "#XGBoost is an advanced implementation of GBM having high predictive power (including a variety of regularisation (choose or define), reducing overfitting and improves overall performance) and is many times faster (parallel processing) and also works best in bias-variance tradeoff situations.\n",
    "\n",
    "#algorithms #ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability and P&C\n",
    "#Independent Events - P(A and B) = P(A) × P(B)\n",
    "#Conditional or dependent events -P(A and B) = P(A) x P(B|A) or P(B|A) = P(A and B) / P(A) -PB|A means probability of b after a.\n",
    "#70% of your friends like Chocolate, and 35% like Chocolate AND like Strawberry.\n",
    "#What percent of those who like Chocolate also like Strawberry?\n",
    "#P(Strawberry|Chocolate) = P(Chocolate and Strawberry) / P(Chocolate)\n",
    "#Mutually Exclusive events -P(A or B) = P(A) + P(B) coz P(A and B) is 0.\n",
    "#A card cannot be a King AND a Queen at the same time!\n",
    " \n",
    "#Dependent Events (such as removing marbles from a bag) are affected by previous events\n",
    "#Independent events (such as a coin toss) are not affected by previous events\n",
    "\n",
    "#Permutation and Combination \n",
    "#When the order doesn't matter, it is a Combination.\n",
    "#When the order does matter it is a Permutation.\n",
    "#Permutations -There are basically two types of permutation: 10P3\n",
    "#Repetition is Allowed: such as the lock above. It could be \"333\". - n × n × ... (r times) = nr\n",
    "#No Repetition: for example the first three people in a running race. You can't be first and second. n!/(n − r)!\n",
    "\n",
    "#Combinations without Repetition - n!/r!(n − r)!\n",
    "\n",
    "#Bayes Theorem - P(A|B) =\t P(A) P(B|A)/P(B) or P(Rain|Cloud) =  P(Rain) P(Cloud|Rain)/P(Cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[image.png]' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation - Data is divide into let say 4 blocks and in first round it will take 1st 3 blocks or 75% of data to be train \n",
    "#and last block means 25% data would be for test and summerize the data. Then 1,2,4 blocks for train and 3rd block for test and so on.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean, Median and Mode Imputation\n",
    "\n",
    "#Using the measures of central tendency involves substituting the missing values with the mean or median for numerical variables\n",
    "#and the mode for categorical variables. The major limitation of using this method is that it leads to biased estimates of the \n",
    "#variances and covariance. The standard errors and test statistics can also be underestimated and overestimated respectively. \n",
    "#This imputation technique works well with when the values are missing completely at random. Scikit-learn comes with an imputed \n",
    "#function in the form sklearn.preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=True). \n",
    "#Strategy is the imputation strategy and the default is the \"mean\" of the axis (0 for columns and 1 for rows). \n",
    "#The other strategies are \"median\" and \"most_frequent\". Another API that can be used for this imputation is fancyimpute.\n",
    "#SimpleFill().\n",
    "\n",
    "#The scikit-learn library provides the Imputer() pre-processing class that can be used to replace missing values.\n",
    "\n",
    "#It is a flexible class that allows you to specify the value to replace (it can be something other than NaN) and the \n",
    "#technique used to replace it (such as mean, median, or mode). The Imputer class operates directly on the NumPy array instead \n",
    "# of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://get.graphlab.com/GraphLab-Create/2.1/zooninwestmelbourne@yahoo.com/F5BD-2EB8-02F2-F8DC-44AE-8C9D-E440-C965/GraphLab-Create-License.tar.gz\n",
      "  Downloading https://get.graphlab.com/GraphLab-Create/2.1/zooninwestmelbourne@yahoo.com/F5BD-2EB8-02F2-F8DC-44AE-8C9D-E440-C965/GraphLab-Create-License.tar.gz\n",
      "Collecting graphlab-create>=2.1 (from GraphLab-Create-License==2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement graphlab-create>=2.1 (from GraphLab-Create-License==2.1) (from versions: )\n",
      "No matching distribution found for graphlab-create>=2.1 (from GraphLab-Create-License==2.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install graphlab-create\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['jean', '-', 'luc', 'picard', '(', 'patrick', 'stewart', ')', 'and', 'the', 'rest', 'of', 'the', 'crew', 'of', 'the', 'u', '.', 's', '.', 's', '.', 'enterprise', 'are', 'back', 'for', 'their', 'third', 'outing', 'in', 'the', 'ninth', 'film', 'based', 'on', 'the', '1960', \"'\", 's', 'series', ',', 'star', 'trek', '.', 'gone', 'are', 'kirk', ',', 'spock', 'and', 'mccoy', 'and', 'in', 'their', 'wake', 'in', 'the', 'very', 'able', 'and', 'very', 'talented', 'cast', 'from', 'star', 'trek', ':', 'the', 'next', 'generation', '.', 'as', 'usual', ',', 'a', 'crisis', 'is', 'brewing', 'and', 'it', 'is', 'up', 'to', 'the', 'crew', 'of', 'the', 'enterprise', 'to', 'make', 'the', 'galaxy', 'safe', 'again', '.', 'this', 'time', 'out', 'the', 'united', 'federation', 'of', 'planets', 'and', 'an', 'alien', 'race', 'led', 'by', 'f', '.', 'murray', 'abraham', 'are', 'trying', 'to', 'move', 'some', 'colonists', 'off', 'a', 'planet', 'against', 'the', 'colonist', \"'\", 's', 'will', '.', 'it', 'turns', 'out', 'that', 'this', 'planet', 'is', 'the', 'fountain', 'of', 'youth', 'and', 'the', 'federation', 'and', 'their', 'alien', 'buddies', 'feel', 'that', 'is', 'should', 'be', 'used', 'for', 'the', 'good', 'of', 'everyone', 'and', 'not', 'just', 'a', 'few', 'hundred', 'colonists', '.', 'of', 'course', 'picard', 'feels', 'that', 'this', 'sort', 'of', 'treachery', 'is', 'wrong', ',', 'so', 'he', 'disobeys', 'direct', 'orders', 'and', 'vows', 'to', 'help', 'protect', 'the', 'colonists', '.', 'insurrection', 'is', 'a', 'lighter', 'movie', 'than', 'the', 'last', 'two', 'star', 'trek', 'films', '.', 'the', 'film', 'focuses', 'on', 'the', 'lofty', 'question', 'of', 'whether', 'the', 'rights', 'of', 'society', 'as', 'a', 'whole', 'outweighs', 'the', 'rights', 'of', 'a', 'small', 'group', '.', 'in', 'this', 'respect', 'it', 'gets', 'back', 'to', 'the', 'roots', 'of', 'star', 'trek', 'by', 'disguising', 'social', 'commentary', 'as', 'science', 'fiction', '.', 'it', 'doesn', \"'\", 't', 'do', 'a', 'bad', 'job', ',', 'other', 'than', 'it', 'tries', 'to', 'inject', 'too', 'much', 'humor', 'into', 'the', 'story', 'line', '.', 'many', 'of', 'the', 'jokes', 'are', 'your', 'typical', 'inside', 'star', 'trek', '-', 'fan', '-', 'only', 'jokes', ',', 'while', 'many', 'of', 'the', 'others', 'just', 'fall', 'flat', '.', 'the', 'other', 'criticism', 'that', 'i', 'had', 'with', 'the', 'story', 'was', 'that', 'it', 'ignores', 'common', 'sense', '.', 'there', 'are', 'only', 'a', 'few', 'hundred', 'people', 'on', 'this', 'whole', 'planet', ',', 'why', 'do', 'they', 'have', 'to', 'be', 'moved', '?', 'the', 'explanation', 'is', 'that', 'the', 'planet', 'has', 'to', 'be', 'bombarded', 'with', 'deadly', 'radiation', 'so', 'that', 'this', 'fountain', 'of', 'youth', 'effect', 'will', 'be', 'strong', 'enough', 'to', 'help', 'heal', 'f', '.', 'murray', 'abraham', \"'\", 's', 'aliens', 'who', 'number', 'only', 'a', 'couple', 'of', 'dozen', '.', 'so', 'the', 'basic', 'story', 'line', 'is', 'bad', 'enough', 'in', 'that', 'we', 'have', 'a', 'few', 'hundred', 'being', 'booted', 'out', 'for', 'a', 'few', 'billion', ',', 'at', 'least', 'that', \"'\", 's', 'plausible', '.', 'but', 'in', 'reality', 'we', 'have', 'a', 'few', 'hundred', 'being', 'moved', 'for', 'the', 'benefits', 'of', 'a', 'few', 'dozen', ',', 'which', 'makes', 'no', 'sense', 'whatsoever', '.', 'the', 'other', 'little', 'hiccup', 'in', 'logic', 'is', 'the', 'inclusion', 'of', 'worf', '(', 'michael', 'dorn', ')', ',', 'the', 'trusty', 'klingon', '.', 'worf', 'was', 'on', 'star', 'trek', ':', 'the', 'next', 'generation', ',', 'so', 'they', 'want', 'to', 'include', 'him', 'in', 'the', 'films', '.', 'no', 'problem', 'so', 'far', '.', 'worf', 'is', 'now', 'a', 'character', 'of', 'star', 'trek', ':', 'deep', 'space', 'nine', ',', 'so', 'the', 'writers', 'have', 'to', 'find', 'a', 'way', 'to', 'have', 'him', 'show', 'up', '.', 'in', 'the', 'last', 'star', 'trek', 'movie', ',', 'first', 'contact', ',', 'the', 'included', 'worf', 'in', 'a', 'credible', 'fashion', ',', 'in', 'this', 'one', ',', 'the', 'writers', 'are', 'so', 'lazy', 'that', 'the', 'completely', 'gloss', 'over', 'why', 'he', 'is', 'even', 'in', 'the', 'movie', '.', 'what', 'little', 'explanation', 'they', 'do', 'give', 'is', 'so', 'small', 'that', 'you', 'would', 'have', 'missed', 'it', 'if', 'you', 'weren', \"'\", 't', 'hanging', 'on', 'every', 'word', 'on', 'the', 'screen', '.', 'my', 'minor', 'problems', 'with', 'the', 'movie', 'aside', ',', 'star', 'trek', ':', 'insurrection', 'does', 'have', 'an', 'overwhelming', 'number', 'of', 'good', 'points', 'as', 'compared', 'to', 'its', 'bad', 'ones', '.', 'while', 'many', 'of', 'the', 'jokes', 'do', 'miss', 'the', 'mark', ',', 'many', 'are', 'pretty', 'good', ',', 'even', 'for', 'non', '-', 'trekkies', '.', 'the', 'special', 'effects', 'are', 'among', 'the', 'best', 'for', 'the', 'star', 'trek', 'series', '.', 'the', 'action', 'is', 'plentiful', 'and', 'well', 'done', '.', 'this', 'is', 'a', 'very', 'good', '-', 'looking', 'movie', '.', 'it', 'should', 'come', 'as', 'no', 'surprise', 'to', 'anyone', 'who', 'ever', 'watched', 'star', 'trek', ':', 'the', 'next', 'generation', 'that', 'the', 'acting', 'is', 'first', 'rate', '.', 'it', 'is', 'very', 'obvious', 'that', 'these', 'actors', 'have', 'been', 'working', 'together', 'for', 'over', 'a', 'decade', '.', 'they', 'interact', 'with', 'each', 'other', 'with', 'a', 'skill', 'that', 'few', 'other', 'ensemble', 'casts', 'can', 'muster', '.', 'most', 'star', 'trek', 'fans', 'probably', 'will', 'not', 'be', 'disappointed', 'with', 'this', 'latest', 'film', 'in', 'the', 'series', '.', 'if', 'you', \"'\", 've', 'always', 'hated', 'star', 'trek', ',', 'there', 'is', 'nothing', 'here', 'that', 'is', 'going', 'to', 'change', 'your', 'mind', '.', 'star', 'trek', ':', 'insurrection', 'is', 'not', 'the', 'best', 'film', 'in', 'the', 'series', ',', 'but', 'it', 'is', 'good', 'enough', 'to', 'dispel', 'the', 'long', 'standing', 'tradition', 'of', 'the', 'odd', 'numbered', 'films', 'in', 'the', 'series', 'being', 'far', 'inferior', 'to', 'the', 'even', 'numbered', 'ones', '.'], 'pos')\n",
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "print(documents[1])\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))\n",
    "print(all_words[\"stupid\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
